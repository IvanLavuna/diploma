{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "# read datasets\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "y1_name, y2_name, y3_name = \"dir_costs\", \"traffic_costs_s_r\", \"lost_trips_costs_s_r\"\n",
    "train_y1, train_y2, train_y3 = train_df[y1_name], train_df[y2_name], train_df[y3_name]\n",
    "test_y1, test_y2, test_y3 = test_df[y1_name], test_df[y2_name], test_df[y3_name]\n",
    "\n",
    "# scale features\n",
    "X_train = train_df.drop(columns=[y1_name, y2_name, y3_name])\n",
    "X_test = test_df.drop(columns=[y1_name, y2_name, y3_name])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:51:10.200094582Z",
     "start_time": "2024-02-07T11:51:10.156500084Z"
    }
   },
   "id": "651cadc1eaadb2ee",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [00:08<00:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:10<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2813\n",
      "[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36977500.275990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "                               Adjusted R-Squared  R-Squared        RMSE  \\\nModel                                                                      \nExtraTreesRegressor                          0.88       0.88  4821200.67   \nGradientBoostingRegressor                    0.87       0.88  4861268.94   \nRandomForestRegressor                        0.87       0.87  4979378.80   \nHistGradientBoostingRegressor                0.87       0.87  5009826.73   \nLGBMRegressor                                0.86       0.87  5050890.07   \nBaggingRegressor                             0.86       0.87  5082296.41   \nSGDRegressor                                 0.85       0.85  5295384.27   \nOrthogonalMatchingPursuit                    0.85       0.85  5302477.10   \nLassoCV                                      0.85       0.85  5316574.29   \nRidge                                        0.85       0.85  5347891.21   \nRidgeCV                                      0.85       0.85  5347891.21   \nLassoLarsIC                                  0.85       0.85  5351317.21   \nLassoLars                                    0.85       0.85  5362803.26   \nLasso                                        0.85       0.85  5362803.29   \nLassoLarsCV                                  0.85       0.85  5362806.52   \nTransformedTargetRegressor                   0.85       0.85  5362806.52   \nLinearRegression                             0.85       0.85  5362806.52   \nOrthogonalMatchingPursuitCV                  0.85       0.85  5371794.00   \nXGBRegressor                                 0.84       0.84  5490464.04   \nPoissonRegressor                             0.83       0.83  5651343.67   \nElasticNet                                   0.82       0.82  5871574.06   \nKNeighborsRegressor                          0.81       0.82  5938499.51   \nHuberRegressor                               0.81       0.81  5971691.90   \nLarsCV                                       0.80       0.80  6166956.29   \nTweedieRegressor                             0.77       0.78  6572457.57   \nRANSACRegressor                              0.76       0.77  6638077.64   \nGammaRegressor                               0.72       0.73  7214120.88   \nDecisionTreeRegressor                        0.70       0.70  7536372.44   \nExtraTreeRegressor                           0.65       0.66  8097868.92   \nAdaBoostRegressor                            0.58       0.59  8883839.65   \nElasticNetCV                                -0.03      -0.00 13877248.49   \nBayesianRidge                               -0.03      -0.00 13879526.71   \nDummyRegressor                              -0.03      -0.00 13879526.71   \nNuSVR                                       -0.09      -0.06 14295125.05   \nSVR                                         -0.14      -0.10 14572832.44   \nGaussianProcessRegressor                    -0.77      -0.71 18156666.10   \nLars                                        -6.15      -5.94 36539330.56   \nKernelRidge                                 -6.46      -6.24 37314346.10   \nPassiveAggressiveRegressor                  -6.90      -6.67 38414856.09   \nLinearSVR                                   -7.54      -7.28 39924565.13   \nMLPRegressor                                -7.54      -7.28 39924691.05   \n\n                               Time Taken  \nModel                                      \nExtraTreesRegressor                  0.50  \nGradientBoostingRegressor            0.56  \nRandomForestRegressor                1.19  \nHistGradientBoostingRegressor        0.25  \nLGBMRegressor                        0.06  \nBaggingRegressor                     0.13  \nSGDRegressor                         0.02  \nOrthogonalMatchingPursuit            0.01  \nLassoCV                              0.24  \nRidge                                0.01  \nRidgeCV                              0.04  \nLassoLarsIC                          0.03  \nLassoLars                            0.04  \nLasso                                0.05  \nLassoLarsCV                          0.06  \nTransformedTargetRegressor           0.01  \nLinearRegression                     0.04  \nOrthogonalMatchingPursuitCV          0.01  \nXGBRegressor                         0.20  \nPoissonRegressor                     2.02  \nElasticNet                           0.02  \nKNeighborsRegressor                  0.02  \nHuberRegressor                       0.03  \nLarsCV                               0.05  \nTweedieRegressor                     0.74  \nRANSACRegressor                      0.05  \nGammaRegressor                       0.27  \nDecisionTreeRegressor                0.03  \nExtraTreeRegressor                   0.02  \nAdaBoostRegressor                    0.21  \nElasticNetCV                         0.09  \nBayesianRidge                        0.01  \nDummyRegressor                       0.01  \nNuSVR                                0.15  \nSVR                                  0.18  \nGaussianProcessRegressor             0.28  \nLars                                 0.03  \nKernelRidge                          0.15  \nPassiveAggressiveRegressor           0.09  \nLinearSVR                            0.03  \nMLPRegressor                         2.61  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>R-Squared</th>\n      <th>RMSE</th>\n      <th>Time Taken</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ExtraTreesRegressor</th>\n      <td>0.88</td>\n      <td>0.88</td>\n      <td>4821200.67</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>GradientBoostingRegressor</th>\n      <td>0.87</td>\n      <td>0.88</td>\n      <td>4861268.94</td>\n      <td>0.56</td>\n    </tr>\n    <tr>\n      <th>RandomForestRegressor</th>\n      <td>0.87</td>\n      <td>0.87</td>\n      <td>4979378.80</td>\n      <td>1.19</td>\n    </tr>\n    <tr>\n      <th>HistGradientBoostingRegressor</th>\n      <td>0.87</td>\n      <td>0.87</td>\n      <td>5009826.73</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>LGBMRegressor</th>\n      <td>0.86</td>\n      <td>0.87</td>\n      <td>5050890.07</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>BaggingRegressor</th>\n      <td>0.86</td>\n      <td>0.87</td>\n      <td>5082296.41</td>\n      <td>0.13</td>\n    </tr>\n    <tr>\n      <th>SGDRegressor</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5295384.27</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>OrthogonalMatchingPursuit</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5302477.10</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>LassoCV</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5316574.29</td>\n      <td>0.24</td>\n    </tr>\n    <tr>\n      <th>Ridge</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5347891.21</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>RidgeCV</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5347891.21</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>LassoLarsIC</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5351317.21</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>LassoLars</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5362803.26</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>Lasso</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5362803.29</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>LassoLarsCV</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5362806.52</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>TransformedTargetRegressor</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5362806.52</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>LinearRegression</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5362806.52</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>OrthogonalMatchingPursuitCV</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>5371794.00</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>XGBRegressor</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>5490464.04</td>\n      <td>0.20</td>\n    </tr>\n    <tr>\n      <th>PoissonRegressor</th>\n      <td>0.83</td>\n      <td>0.83</td>\n      <td>5651343.67</td>\n      <td>2.02</td>\n    </tr>\n    <tr>\n      <th>ElasticNet</th>\n      <td>0.82</td>\n      <td>0.82</td>\n      <td>5871574.06</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>KNeighborsRegressor</th>\n      <td>0.81</td>\n      <td>0.82</td>\n      <td>5938499.51</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>HuberRegressor</th>\n      <td>0.81</td>\n      <td>0.81</td>\n      <td>5971691.90</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>LarsCV</th>\n      <td>0.80</td>\n      <td>0.80</td>\n      <td>6166956.29</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>TweedieRegressor</th>\n      <td>0.77</td>\n      <td>0.78</td>\n      <td>6572457.57</td>\n      <td>0.74</td>\n    </tr>\n    <tr>\n      <th>RANSACRegressor</th>\n      <td>0.76</td>\n      <td>0.77</td>\n      <td>6638077.64</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>GammaRegressor</th>\n      <td>0.72</td>\n      <td>0.73</td>\n      <td>7214120.88</td>\n      <td>0.27</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeRegressor</th>\n      <td>0.70</td>\n      <td>0.70</td>\n      <td>7536372.44</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>ExtraTreeRegressor</th>\n      <td>0.65</td>\n      <td>0.66</td>\n      <td>8097868.92</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>AdaBoostRegressor</th>\n      <td>0.58</td>\n      <td>0.59</td>\n      <td>8883839.65</td>\n      <td>0.21</td>\n    </tr>\n    <tr>\n      <th>ElasticNetCV</th>\n      <td>-0.03</td>\n      <td>-0.00</td>\n      <td>13877248.49</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>BayesianRidge</th>\n      <td>-0.03</td>\n      <td>-0.00</td>\n      <td>13879526.71</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>DummyRegressor</th>\n      <td>-0.03</td>\n      <td>-0.00</td>\n      <td>13879526.71</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>NuSVR</th>\n      <td>-0.09</td>\n      <td>-0.06</td>\n      <td>14295125.05</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>SVR</th>\n      <td>-0.14</td>\n      <td>-0.10</td>\n      <td>14572832.44</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>GaussianProcessRegressor</th>\n      <td>-0.77</td>\n      <td>-0.71</td>\n      <td>18156666.10</td>\n      <td>0.28</td>\n    </tr>\n    <tr>\n      <th>Lars</th>\n      <td>-6.15</td>\n      <td>-5.94</td>\n      <td>36539330.56</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>KernelRidge</th>\n      <td>-6.46</td>\n      <td>-6.24</td>\n      <td>37314346.10</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveRegressor</th>\n      <td>-6.90</td>\n      <td>-6.67</td>\n      <td>38414856.09</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>LinearSVR</th>\n      <td>-7.54</td>\n      <td>-7.28</td>\n      <td>39924565.13</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>MLPRegressor</th>\n      <td>-7.54</td>\n      <td>-7.28</td>\n      <td>39924691.05</td>\n      <td>2.61</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LazyRegressor part\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train, X_test, train_y1, test_y1)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:51:26.845915961Z",
     "start_time": "2024-02-07T11:51:16.233142857Z"
    }
   },
   "id": "86ee7b7cbe2fe8e9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 9/42 [00:00<00:03,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GammaRegressor model failed to execute\n",
      "Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 30/42 [00:04<00:01,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoissonRegressor model failed to execute\n",
      "Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n",
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:06<00:00,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2813\n",
      "[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 2376948.061796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "                               Adjusted R-Squared  R-Squared        RMSE  \\\nModel                                                                      \nXGBRegressor                                 0.84       0.84  6061095.29   \nLGBMRegressor                                0.83       0.84  6094770.44   \nExtraTreesRegressor                          0.82       0.82  6382617.83   \nHistGradientBoostingRegressor                0.82       0.82  6405705.96   \nBaggingRegressor                             0.82       0.82  6424554.95   \nRandomForestRegressor                        0.81       0.82  6441033.11   \nGradientBoostingRegressor                    0.81       0.82  6521976.44   \nLars                                         0.77       0.77  7240474.22   \nLassoLars                                    0.77       0.77  7241961.89   \nTransformedTargetRegressor                   0.77       0.77  7241961.89   \nLinearRegression                             0.77       0.77  7241961.89   \nLasso                                        0.77       0.77  7241961.94   \nLassoLarsCV                                  0.77       0.77  7242131.94   \nRidge                                        0.77       0.77  7242401.35   \nLassoLarsIC                                  0.77       0.77  7243056.56   \nLarsCV                                       0.77       0.77  7243412.18   \nRidgeCV                                      0.76       0.77  7250178.25   \nLassoCV                                      0.76       0.77  7251181.30   \nSGDRegressor                                 0.76       0.77  7258232.01   \nOrthogonalMatchingPursuitCV                  0.76       0.77  7283642.93   \nOrthogonalMatchingPursuit                    0.76       0.77  7333705.69   \nRANSACRegressor                              0.75       0.76  7455186.22   \nKernelRidge                                  0.74       0.75  7589203.21   \nDecisionTreeRegressor                        0.74       0.75  7620937.08   \nHuberRegressor                               0.69       0.69  8385748.07   \nElasticNet                                   0.67       0.68  8558608.68   \nAdaBoostRegressor                            0.67       0.68  8639749.93   \nKNeighborsRegressor                          0.64       0.65  8956843.41   \nExtraTreeRegressor                           0.61       0.63  9283700.86   \nTweedieRegressor                             0.56       0.57  9906860.20   \nGaussianProcessRegressor                     0.52       0.53 10380507.53   \nPassiveAggressiveRegressor                   0.07       0.10 14374761.87   \nElasticNetCV                                -0.03      -0.00 15187800.42   \nBayesianRidge                               -0.03      -0.00 15188667.82   \nDummyRegressor                              -0.03      -0.00 15188667.82   \nNuSVR                                       -0.04      -0.01 15237754.90   \nSVR                                         -0.05      -0.01 15278051.82   \nLinearSVR                                   -0.07      -0.04 15484571.08   \nMLPRegressor                                -0.07      -0.04 15485164.50   \n\n                               Time Taken  \nModel                                      \nXGBRegressor                         0.21  \nLGBMRegressor                        0.06  \nExtraTreesRegressor                  0.45  \nHistGradientBoostingRegressor        0.22  \nBaggingRegressor                     0.12  \nRandomForestRegressor                1.16  \nGradientBoostingRegressor            0.57  \nLars                                 0.02  \nLassoLars                            0.02  \nTransformedTargetRegressor           0.01  \nLinearRegression                     0.02  \nLasso                                0.05  \nLassoLarsCV                          0.05  \nRidge                                0.01  \nLassoLarsIC                          0.03  \nLarsCV                               0.05  \nRidgeCV                              0.03  \nLassoCV                              0.15  \nSGDRegressor                         0.03  \nOrthogonalMatchingPursuitCV          0.01  \nOrthogonalMatchingPursuit            0.01  \nRANSACRegressor                      0.04  \nKernelRidge                          0.09  \nDecisionTreeRegressor                0.03  \nHuberRegressor                       0.02  \nElasticNet                           0.02  \nAdaBoostRegressor                    0.15  \nKNeighborsRegressor                  0.02  \nExtraTreeRegressor                   0.02  \nTweedieRegressor                     0.61  \nGaussianProcessRegressor             0.21  \nPassiveAggressiveRegressor           0.10  \nElasticNetCV                         0.09  \nBayesianRidge                        0.01  \nDummyRegressor                       0.01  \nNuSVR                                0.14  \nSVR                                  0.18  \nLinearSVR                            0.04  \nMLPRegressor                         1.42  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>R-Squared</th>\n      <th>RMSE</th>\n      <th>Time Taken</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>XGBRegressor</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>6061095.29</td>\n      <td>0.21</td>\n    </tr>\n    <tr>\n      <th>LGBMRegressor</th>\n      <td>0.83</td>\n      <td>0.84</td>\n      <td>6094770.44</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>ExtraTreesRegressor</th>\n      <td>0.82</td>\n      <td>0.82</td>\n      <td>6382617.83</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>HistGradientBoostingRegressor</th>\n      <td>0.82</td>\n      <td>0.82</td>\n      <td>6405705.96</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>BaggingRegressor</th>\n      <td>0.82</td>\n      <td>0.82</td>\n      <td>6424554.95</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>RandomForestRegressor</th>\n      <td>0.81</td>\n      <td>0.82</td>\n      <td>6441033.11</td>\n      <td>1.16</td>\n    </tr>\n    <tr>\n      <th>GradientBoostingRegressor</th>\n      <td>0.81</td>\n      <td>0.82</td>\n      <td>6521976.44</td>\n      <td>0.57</td>\n    </tr>\n    <tr>\n      <th>Lars</th>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>7240474.22</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>LassoLars</th>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>7241961.89</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>TransformedTargetRegressor</th>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>7241961.89</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>LinearRegression</th>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>7241961.89</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>Lasso</th>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>7241961.94</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>LassoLarsCV</th>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>7242131.94</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>Ridge</th>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>7242401.35</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>LassoLarsIC</th>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>7243056.56</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>LarsCV</th>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>7243412.18</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>RidgeCV</th>\n      <td>0.76</td>\n      <td>0.77</td>\n      <td>7250178.25</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>LassoCV</th>\n      <td>0.76</td>\n      <td>0.77</td>\n      <td>7251181.30</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>SGDRegressor</th>\n      <td>0.76</td>\n      <td>0.77</td>\n      <td>7258232.01</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>OrthogonalMatchingPursuitCV</th>\n      <td>0.76</td>\n      <td>0.77</td>\n      <td>7283642.93</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>OrthogonalMatchingPursuit</th>\n      <td>0.76</td>\n      <td>0.77</td>\n      <td>7333705.69</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>RANSACRegressor</th>\n      <td>0.75</td>\n      <td>0.76</td>\n      <td>7455186.22</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>KernelRidge</th>\n      <td>0.74</td>\n      <td>0.75</td>\n      <td>7589203.21</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeRegressor</th>\n      <td>0.74</td>\n      <td>0.75</td>\n      <td>7620937.08</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>HuberRegressor</th>\n      <td>0.69</td>\n      <td>0.69</td>\n      <td>8385748.07</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>ElasticNet</th>\n      <td>0.67</td>\n      <td>0.68</td>\n      <td>8558608.68</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>AdaBoostRegressor</th>\n      <td>0.67</td>\n      <td>0.68</td>\n      <td>8639749.93</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>KNeighborsRegressor</th>\n      <td>0.64</td>\n      <td>0.65</td>\n      <td>8956843.41</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>ExtraTreeRegressor</th>\n      <td>0.61</td>\n      <td>0.63</td>\n      <td>9283700.86</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>TweedieRegressor</th>\n      <td>0.56</td>\n      <td>0.57</td>\n      <td>9906860.20</td>\n      <td>0.61</td>\n    </tr>\n    <tr>\n      <th>GaussianProcessRegressor</th>\n      <td>0.52</td>\n      <td>0.53</td>\n      <td>10380507.53</td>\n      <td>0.21</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveRegressor</th>\n      <td>0.07</td>\n      <td>0.10</td>\n      <td>14374761.87</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>ElasticNetCV</th>\n      <td>-0.03</td>\n      <td>-0.00</td>\n      <td>15187800.42</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>BayesianRidge</th>\n      <td>-0.03</td>\n      <td>-0.00</td>\n      <td>15188667.82</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>DummyRegressor</th>\n      <td>-0.03</td>\n      <td>-0.00</td>\n      <td>15188667.82</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>NuSVR</th>\n      <td>-0.04</td>\n      <td>-0.01</td>\n      <td>15237754.90</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>SVR</th>\n      <td>-0.05</td>\n      <td>-0.01</td>\n      <td>15278051.82</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>LinearSVR</th>\n      <td>-0.07</td>\n      <td>-0.04</td>\n      <td>15484571.08</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>MLPRegressor</th>\n      <td>-0.07</td>\n      <td>-0.04</td>\n      <td>15485164.50</td>\n      <td>1.42</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LazyRegressor part\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train, X_test, train_y2, test_y2)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:51:38.606159642Z",
     "start_time": "2024-02-07T11:51:32.044152959Z"
    }
   },
   "id": "650986b60dc9004c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 32/42 [00:06<00:03,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:09<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2813\n",
      "[LightGBM] [Info] Number of data points in the train set: 1616, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 61132553.259901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "                               Adjusted R-Squared  R-Squared        RMSE  \\\nModel                                                                      \nPoissonRegressor                             0.67       0.68 18149988.10   \nGradientBoostingRegressor                    0.64       0.65 19022849.86   \nExtraTreesRegressor                          0.64       0.65 19024721.52   \nHistGradientBoostingRegressor                0.64       0.65 19046551.37   \nRidgeCV                                      0.63       0.64 19307474.30   \nLGBMRegressor                                0.63       0.64 19322770.29   \nRidge                                        0.63       0.64 19323100.64   \nLassoCV                                      0.63       0.64 19329320.90   \nLassoLarsIC                                  0.63       0.64 19330354.90   \nLassoLarsCV                                  0.63       0.64 19330617.69   \nLasso                                        0.63       0.64 19331945.81   \nLassoLars                                    0.63       0.64 19331945.86   \nLars                                         0.63       0.64 19331946.70   \nLinearRegression                             0.63       0.64 19331946.70   \nTransformedTargetRegressor                   0.63       0.64 19331946.70   \nSGDRegressor                                 0.63       0.64 19342644.80   \nOrthogonalMatchingPursuitCV                  0.62       0.63 19476875.09   \nRandomForestRegressor                        0.62       0.63 19621146.57   \nLarsCV                                       0.61       0.63 19634204.25   \nXGBRegressor                                 0.61       0.62 19850539.73   \nBaggingRegressor                             0.59       0.60 20338792.39   \nElasticNet                                   0.55       0.57 21129207.72   \nKNeighborsRegressor                          0.50       0.52 22256312.63   \nRANSACRegressor                              0.50       0.52 22311564.94   \nGammaRegressor                               0.50       0.52 22313325.15   \nTweedieRegressor                             0.49       0.51 22548637.55   \nHuberRegressor                               0.42       0.44 24010909.88   \nOrthogonalMatchingPursuit                    0.37       0.39 25168194.28   \nDecisionTreeRegressor                        0.25       0.27 27387977.48   \nAdaBoostRegressor                            0.23       0.25 27832166.51   \nExtraTreeRegressor                           0.16       0.18 29003428.74   \nElasticNetCV                                -0.04      -0.00 32186095.51   \nBayesianRidge                               -0.04      -0.00 32187934.04   \nDummyRegressor                              -0.04      -0.00 32187934.04   \nNuSVR                                       -0.09      -0.06 33086586.82   \nSVR                                         -0.13      -0.10 33623081.46   \nGaussianProcessRegressor                    -0.42      -0.37 37638335.62   \nKernelRidge                                 -3.14      -3.02 64361018.50   \nPassiveAggressiveRegressor                  -3.84      -3.69 69579913.91   \nLinearSVR                                   -4.04      -3.89 71015997.25   \nMLPRegressor                                -4.04      -3.89 71016000.58   \n\n                               Time Taken  \nModel                                      \nPoissonRegressor                     1.34  \nGradientBoostingRegressor            0.62  \nExtraTreesRegressor                  0.50  \nHistGradientBoostingRegressor        0.23  \nRidgeCV                              0.03  \nLGBMRegressor                        0.06  \nRidge                                0.01  \nLassoCV                              0.18  \nLassoLarsIC                          0.02  \nLassoLarsCV                          0.07  \nLasso                                0.07  \nLassoLars                            0.02  \nLars                                 0.08  \nLinearRegression                     0.01  \nTransformedTargetRegressor           0.01  \nSGDRegressor                         0.02  \nOrthogonalMatchingPursuitCV          0.01  \nRandomForestRegressor                1.24  \nLarsCV                               0.03  \nXGBRegressor                         0.33  \nBaggingRegressor                     0.12  \nElasticNet                           0.03  \nKNeighborsRegressor                  0.03  \nRANSACRegressor                      0.14  \nGammaRegressor                       0.30  \nTweedieRegressor                     0.66  \nHuberRegressor                       0.10  \nOrthogonalMatchingPursuit            0.01  \nDecisionTreeRegressor                0.03  \nAdaBoostRegressor                    0.20  \nExtraTreeRegressor                   0.02  \nElasticNetCV                         0.15  \nBayesianRidge                        0.01  \nDummyRegressor                       0.01  \nNuSVR                                0.14  \nSVR                                  0.22  \nGaussianProcessRegressor             0.33  \nKernelRidge                          0.11  \nPassiveAggressiveRegressor           0.09  \nLinearSVR                            0.01  \nMLPRegressor                         2.07  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>R-Squared</th>\n      <th>RMSE</th>\n      <th>Time Taken</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>PoissonRegressor</th>\n      <td>0.67</td>\n      <td>0.68</td>\n      <td>18149988.10</td>\n      <td>1.34</td>\n    </tr>\n    <tr>\n      <th>GradientBoostingRegressor</th>\n      <td>0.64</td>\n      <td>0.65</td>\n      <td>19022849.86</td>\n      <td>0.62</td>\n    </tr>\n    <tr>\n      <th>ExtraTreesRegressor</th>\n      <td>0.64</td>\n      <td>0.65</td>\n      <td>19024721.52</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>HistGradientBoostingRegressor</th>\n      <td>0.64</td>\n      <td>0.65</td>\n      <td>19046551.37</td>\n      <td>0.23</td>\n    </tr>\n    <tr>\n      <th>RidgeCV</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19307474.30</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>LGBMRegressor</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19322770.29</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>Ridge</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19323100.64</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>LassoCV</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19329320.90</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>LassoLarsIC</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19330354.90</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>LassoLarsCV</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19330617.69</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>Lasso</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19331945.81</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>LassoLars</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19331945.86</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>Lars</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19331946.70</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>LinearRegression</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19331946.70</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>TransformedTargetRegressor</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19331946.70</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>SGDRegressor</th>\n      <td>0.63</td>\n      <td>0.64</td>\n      <td>19342644.80</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>OrthogonalMatchingPursuitCV</th>\n      <td>0.62</td>\n      <td>0.63</td>\n      <td>19476875.09</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>RandomForestRegressor</th>\n      <td>0.62</td>\n      <td>0.63</td>\n      <td>19621146.57</td>\n      <td>1.24</td>\n    </tr>\n    <tr>\n      <th>LarsCV</th>\n      <td>0.61</td>\n      <td>0.63</td>\n      <td>19634204.25</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>XGBRegressor</th>\n      <td>0.61</td>\n      <td>0.62</td>\n      <td>19850539.73</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>BaggingRegressor</th>\n      <td>0.59</td>\n      <td>0.60</td>\n      <td>20338792.39</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>ElasticNet</th>\n      <td>0.55</td>\n      <td>0.57</td>\n      <td>21129207.72</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>KNeighborsRegressor</th>\n      <td>0.50</td>\n      <td>0.52</td>\n      <td>22256312.63</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>RANSACRegressor</th>\n      <td>0.50</td>\n      <td>0.52</td>\n      <td>22311564.94</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>GammaRegressor</th>\n      <td>0.50</td>\n      <td>0.52</td>\n      <td>22313325.15</td>\n      <td>0.30</td>\n    </tr>\n    <tr>\n      <th>TweedieRegressor</th>\n      <td>0.49</td>\n      <td>0.51</td>\n      <td>22548637.55</td>\n      <td>0.66</td>\n    </tr>\n    <tr>\n      <th>HuberRegressor</th>\n      <td>0.42</td>\n      <td>0.44</td>\n      <td>24010909.88</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>OrthogonalMatchingPursuit</th>\n      <td>0.37</td>\n      <td>0.39</td>\n      <td>25168194.28</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeRegressor</th>\n      <td>0.25</td>\n      <td>0.27</td>\n      <td>27387977.48</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>AdaBoostRegressor</th>\n      <td>0.23</td>\n      <td>0.25</td>\n      <td>27832166.51</td>\n      <td>0.20</td>\n    </tr>\n    <tr>\n      <th>ExtraTreeRegressor</th>\n      <td>0.16</td>\n      <td>0.18</td>\n      <td>29003428.74</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>ElasticNetCV</th>\n      <td>-0.04</td>\n      <td>-0.00</td>\n      <td>32186095.51</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>BayesianRidge</th>\n      <td>-0.04</td>\n      <td>-0.00</td>\n      <td>32187934.04</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>DummyRegressor</th>\n      <td>-0.04</td>\n      <td>-0.00</td>\n      <td>32187934.04</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>NuSVR</th>\n      <td>-0.09</td>\n      <td>-0.06</td>\n      <td>33086586.82</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>SVR</th>\n      <td>-0.13</td>\n      <td>-0.10</td>\n      <td>33623081.46</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>GaussianProcessRegressor</th>\n      <td>-0.42</td>\n      <td>-0.37</td>\n      <td>37638335.62</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>KernelRidge</th>\n      <td>-3.14</td>\n      <td>-3.02</td>\n      <td>64361018.50</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveRegressor</th>\n      <td>-3.84</td>\n      <td>-3.69</td>\n      <td>69579913.91</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>LinearSVR</th>\n      <td>-4.04</td>\n      <td>-3.89</td>\n      <td>71015997.25</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>MLPRegressor</th>\n      <td>-4.04</td>\n      <td>-3.89</td>\n      <td>71016000.58</td>\n      <td>2.07</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LazyRegressor part\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train, X_test, train_y3, test_y3)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:51:58.221221600Z",
     "start_time": "2024-02-07T11:51:48.530739135Z"
    }
   },
   "id": "12e142ff343533f9",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
