{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-28T12:09:19.168686Z",
     "start_time": "2024-02-28T12:09:18.596155Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# read datasets\n",
    "train_df = pd.read_csv('data/train2.csv')\n",
    "test_df = pd.read_csv('data/test2.csv')\n",
    "\n",
    "y1_name, y2_name, y3_name = \"dir_costs\", \"traffic_costs_s_r\", \"lost_trips_costs_s_r\"\n",
    "train_y1, train_y2, train_y3 = train_df[y1_name], train_df[y2_name], train_df[y3_name]\n",
    "test_y1, test_y2, test_y3 = test_df[y1_name], test_df[y2_name], test_df[y3_name]\n",
    "\n",
    "# scale features\n",
    "X_train = train_df.drop(columns=[y1_name, y2_name, y3_name])\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = test_df.drop(columns=[y1_name, y2_name, y3_name])\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Train GBR model using random hyperparameters </h1>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22699c2a0da02148"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test metrics ------\n",
      "Mean Squared Error (MSE):              782183991403215.2500000000\n",
      "Root Mean Squared Error (RMSE):        27967552.4743087813\n",
      "Mean Absolute Error (MAE):             14350359.1337993350\n",
      "R-squared (R²):                        0.6896669741\n",
      "Mean Absolute Percentage Error (MAPE): 0.1501666605\n",
      "Max Error (ME):                        230163727.4108173549\n",
      "Median Absolute Error (MedAE):         6162288.9150794968\n",
      "------ train metrics ------\n",
      "Mean Squared Error (MSE):              271620877573933.7812500000\n",
      "Root Mean Squared Error (RMSE):        16480924.6577348858\n",
      "Mean Absolute Error (MAE):             9855529.0997086167\n",
      "R-squared (R²):                        0.8992476870\n",
      "Mean Absolute Percentage Error (MAPE): 0.1181805488\n",
      "Max Error (ME):                        114024938.1598487198\n",
      "Median Absolute Error (MedAE):         5655040.8151182309\n"
     ]
    }
   ],
   "source": [
    "from metrics import print_metrics\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create an instance of GradientBoostingRegressor\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "gb_regressor.fit(X_train, train_y3)\n",
    "\n",
    "print(\"------ test metrics ------\")\n",
    "print_metrics(test_y3, gb_regressor.predict(X_test))\n",
    "\n",
    "print(\"------ train metrics ------\")\n",
    "print_metrics(train_y3, gb_regressor.predict(X_train))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T12:09:30.965806Z",
     "start_time": "2024-02-28T12:09:30.428565Z"
    }
   },
   "id": "d77351f53ec31143",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Optimize Gradient boost parameters using Differential evolution</h1>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c21cb69d591a22e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# define objective function\n",
    "def objective_function(params, train_X, train_y, test_X, test_y):\n",
    "    regressor = GradientBoostingRegressor(n_estimators=int(params[0]), learning_rate=params[1], max_depth=int(params[2]), random_state=42)\n",
    "    regressor.fit(train_X, train_y)\n",
    "    pred_y = regressor.predict(test_X)\n",
    "    r2 = r2_score(test_y, pred_y)\n",
    "    return -r2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T12:10:41.523071Z",
     "start_time": "2024-02-28T12:10:41.517377Z"
    }
   },
   "id": "c0068388699b3bb9",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.692742\n",
      "differential_evolution step 2: f(x)= -0.695701\n",
      "differential_evolution step 3: f(x)= -0.695701\n",
      "differential_evolution step 4: f(x)= -0.697608\n",
      "differential_evolution step 5: f(x)= -0.705371\n",
      "differential_evolution step 6: f(x)= -0.705371\n",
      "differential_evolution step 7: f(x)= -0.70554\n",
      "differential_evolution step 8: f(x)= -0.70554\n",
      "differential_evolution step 9: f(x)= -0.711373\n",
      "differential_evolution step 10: f(x)= -0.711373\n",
      "differential_evolution step 11: f(x)= -0.711373\n",
      "differential_evolution step 12: f(x)= -0.711373\n",
      "differential_evolution step 13: f(x)= -0.711373\n",
      "differential_evolution step 14: f(x)= -0.711373\n",
      "differential_evolution step 15: f(x)= -0.711373\n",
      "differential_evolution step 16: f(x)= -0.711373\n",
      "differential_evolution step 17: f(x)= -0.711373\n",
      "differential_evolution step 18: f(x)= -0.711373\n",
      "differential_evolution step 19: f(x)= -0.711373\n",
      "differential_evolution step 20: f(x)= -0.711373\n",
      "differential_evolution step 21: f(x)= -0.711373\n",
      "differential_evolution step 22: f(x)= -0.711373\n",
      "differential_evolution step 23: f(x)= -0.711373\n",
      "differential_evolution step 24: f(x)= -0.711373\n",
      "differential_evolution step 25: f(x)= -0.711373\n",
      "differential_evolution step 26: f(x)= -0.711373\n",
      "differential_evolution step 27: f(x)= -0.711373\n",
      "differential_evolution step 28: f(x)= -0.711373\n",
      "differential_evolution step 29: f(x)= -0.711373\n",
      "differential_evolution step 30: f(x)= -0.711373\n",
      "differential_evolution step 31: f(x)= -0.711373\n",
      "differential_evolution step 32: f(x)= -0.711766\n",
      "differential_evolution step 33: f(x)= -0.711766\n",
      "differential_evolution step 34: f(x)= -0.711766\n",
      "differential_evolution step 35: f(x)= -0.711766\n",
      "differential_evolution step 36: f(x)= -0.711766\n",
      "differential_evolution step 37: f(x)= -0.711766\n",
      "differential_evolution step 38: f(x)= -0.711766\n",
      "differential_evolution step 39: f(x)= -0.711766\n",
      "differential_evolution step 40: f(x)= -0.711766\n",
      "differential_evolution step 41: f(x)= -0.711766\n",
      "differential_evolution step 42: f(x)= -0.711766\n",
      "differential_evolution step 43: f(x)= -0.711766\n",
      "differential_evolution step 44: f(x)= -0.711766\n",
      "differential_evolution step 45: f(x)= -0.711766\n",
      "differential_evolution step 46: f(x)= -0.711766\n",
      "differential_evolution step 47: f(x)= -0.711766\n",
      "differential_evolution step 48: f(x)= -0.712118\n",
      "differential_evolution step 49: f(x)= -0.712118\n",
      "differential_evolution step 50: f(x)= -0.712796\n",
      "Polishing solution with 'L-BFGS-B'\n",
      " message: Maximum number of iterations has been exceeded.\n",
      " success: False\n",
      "     fun: -0.7127956749122254\n",
      "       x: [ 2.402e+02  1.513e-01  2.313e+00]\n",
      "     nit: 50\n",
      "    nfev: 2495\n"
     ]
    }
   ],
   "source": [
    "optimization_res = differential_evolution(func=objective_function, \n",
    "                                          bounds=[(2, 300), (0.0001, 0.5), (2, 10)], \n",
    "                                          updating='deferred',\n",
    "                                          workers=10, \n",
    "                                          disp=True,\n",
    "                                          tol=0.00001,\n",
    "                                          atol=0.00001,\n",
    "                                          maxiter=50,\n",
    "                                          args=(X_train, train_y3, X_test, test_y3))\n",
    "print(optimization_res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T12:18:24.476508Z",
     "start_time": "2024-02-28T12:10:50.732712Z"
    }
   },
   "id": "943c71e4c7e14e11",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([2.40196902e+02, 1.51313415e-01, 2.31307748e+00])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_res.x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T12:18:48.792173Z",
     "start_time": "2024-02-28T12:18:48.783227Z"
    }
   },
   "id": "c617ea1ed43590c9",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test metrics ------\n",
      "Mean Squared Error (MSE):              723888876129478.1250000000\n",
      "Root Mean Squared Error (RMSE):        26905183.0718446895\n",
      "Mean Absolute Error (MAE):             14499530.3755175173\n",
      "R-squared (R²):                        0.7127956749\n",
      "Mean Absolute Percentage Error (MAPE): 0.1680235227\n",
      "Max Error (ME):                        234231889.0085158348\n",
      "Median Absolute Error (MedAE):         7469819.9944704622\n",
      "------ train metrics ------\n",
      "Mean Squared Error (MSE):              243482517207629.6875000000\n",
      "Root Mean Squared Error (RMSE):        15603926.3394707702\n",
      "Mean Absolute Error (MAE):             9855775.2816351615\n",
      "R-squared (R²):                        0.9096850470\n",
      "Mean Absolute Percentage Error (MAPE): 0.1261398595\n",
      "Max Error (ME):                        108583489.6071152687\n",
      "Median Absolute Error (MedAE):         6326936.7840599492\n"
     ]
    }
   ],
   "source": [
    "from metrics import print_metrics\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create an instance of GradientBoostingRegressor\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=int(optimization_res.x[0]), learning_rate=optimization_res.x[1], max_depth=int(optimization_res.x[2]), random_state=42)\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "gb_regressor.fit(X_train, train_y3)\n",
    "\n",
    "print(\"------ test metrics ------\")\n",
    "print_metrics(test_y3, gb_regressor.predict(X_test))\n",
    "\n",
    "print(\"------ train metrics ------\")\n",
    "print_metrics(train_y3, gb_regressor.predict(X_train))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T12:18:56.757678Z",
     "start_time": "2024-02-28T12:18:55.991891Z"
    }
   },
   "id": "98fa02746a5dd0f1",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "45bed6a525b3be7a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
