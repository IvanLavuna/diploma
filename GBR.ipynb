{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-23T08:35:57.565128212Z",
     "start_time": "2024-02-23T08:35:56.542917510Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# read datasets\n",
    "train_df = pd.read_csv('data/train2.csv')\n",
    "test_df = pd.read_csv('data/test2.csv')\n",
    "\n",
    "y1_name, y2_name, y3_name = \"dir_costs\", \"traffic_costs_s_r\", \"lost_trips_costs_s_r\"\n",
    "train_y1, train_y2, train_y3 = train_df[y1_name], train_df[y2_name], train_df[y3_name]\n",
    "test_y1, test_y2, test_y3 = test_df[y1_name], test_df[y2_name], test_df[y3_name]\n",
    "\n",
    "# scale features\n",
    "X_train = train_df.drop(columns=[y1_name, y2_name, y3_name])\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = test_df.drop(columns=[y1_name, y2_name, y3_name])\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Train GBR model using random hyperparameters </h1>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22699c2a0da02148"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test metrics ------\n",
      "Mean Squared Error (MSE):              27439980506090.0664062500\n",
      "Root Mean Squared Error (RMSE):        5238318.4807808381\n",
      "Mean Absolute Error (MAE):             2876794.1302192868\n",
      "R-squared (R²):                        0.8626833396\n",
      "Mean Absolute Percentage Error (MAPE): 0.0690625984\n",
      "Max Error (ME):                        24963096.2137863524\n",
      "Median Absolute Error (MedAE):         1357845.8501538225\n",
      "------ train metrics ------\n",
      "Mean Squared Error (MSE):              12169729567402.5410156250\n",
      "Root Mean Squared Error (RMSE):        3488513.9482883741\n",
      "Mean Absolute Error (MAE):             2048725.9760733228\n",
      "R-squared (R²):                        0.9315339912\n",
      "Mean Absolute Percentage Error (MAPE): 0.0511555516\n",
      "Max Error (ME):                        20353932.9277601838\n",
      "Median Absolute Error (MedAE):         1141793.6472524647\n"
     ]
    }
   ],
   "source": [
    "from metrics import print_metrics\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create an instance of GradientBoostingRegressor\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "gb_regressor.fit(X_train, train_y1)\n",
    "\n",
    "print(\"------ test metrics ------\")\n",
    "print_metrics(test_y1, gb_regressor.predict(X_test))\n",
    "\n",
    "print(\"------ train metrics ------\")\n",
    "print_metrics(train_y1, gb_regressor.predict(X_train))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T08:37:09.560803676Z",
     "start_time": "2024-02-23T08:37:08.528364305Z"
    }
   },
   "id": "d77351f53ec31143",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Optimize Gradient boost parameters using Differential evolution</h1>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c21cb69d591a22e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# define objective function\n",
    "def objective_function(params, train_X, train_y, test_X, test_y):\n",
    "    regressor = GradientBoostingRegressor(n_estimators=int(params[0]), learning_rate=params[1], max_depth=int(params[2]), random_state=42)\n",
    "    regressor.fit(train_X, train_y)\n",
    "    pred_y = regressor.predict(test_X)\n",
    "    r2 = r2_score(test_y, pred_y)\n",
    "    return -r2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T08:37:47.110432712Z",
     "start_time": "2024-02-23T08:37:47.063721599Z"
    }
   },
   "id": "c0068388699b3bb9",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.865639\n",
      "differential_evolution step 2: f(x)= -0.865639\n",
      "differential_evolution step 3: f(x)= -0.865959\n",
      "differential_evolution step 4: f(x)= -0.865959\n",
      "differential_evolution step 5: f(x)= -0.865959\n",
      "differential_evolution step 6: f(x)= -0.865959\n",
      "differential_evolution step 7: f(x)= -0.866972\n",
      "differential_evolution step 8: f(x)= -0.866972\n",
      "differential_evolution step 9: f(x)= -0.86701\n",
      "differential_evolution step 10: f(x)= -0.86701\n",
      "differential_evolution step 11: f(x)= -0.86701\n",
      "differential_evolution step 12: f(x)= -0.86701\n",
      "differential_evolution step 13: f(x)= -0.86701\n",
      "differential_evolution step 14: f(x)= -0.867454\n",
      "differential_evolution step 15: f(x)= -0.867454\n",
      "differential_evolution step 16: f(x)= -0.867454\n",
      "differential_evolution step 17: f(x)= -0.867454\n",
      "differential_evolution step 18: f(x)= -0.867797\n",
      "differential_evolution step 19: f(x)= -0.867797\n",
      "differential_evolution step 20: f(x)= -0.867797\n",
      "differential_evolution step 21: f(x)= -0.867797\n",
      "differential_evolution step 22: f(x)= -0.867797\n",
      "differential_evolution step 23: f(x)= -0.868038\n",
      "differential_evolution step 24: f(x)= -0.868038\n",
      "differential_evolution step 25: f(x)= -0.868038\n",
      "differential_evolution step 26: f(x)= -0.868759\n",
      "differential_evolution step 27: f(x)= -0.868759\n",
      "differential_evolution step 28: f(x)= -0.868759\n",
      "differential_evolution step 29: f(x)= -0.868759\n",
      "differential_evolution step 30: f(x)= -0.869375\n",
      "differential_evolution step 31: f(x)= -0.869375\n",
      "differential_evolution step 32: f(x)= -0.869375\n",
      "differential_evolution step 33: f(x)= -0.869375\n",
      "differential_evolution step 34: f(x)= -0.869375\n",
      "differential_evolution step 35: f(x)= -0.869375\n",
      "differential_evolution step 36: f(x)= -0.869375\n",
      "differential_evolution step 37: f(x)= -0.869375\n",
      "differential_evolution step 38: f(x)= -0.869375\n",
      "differential_evolution step 39: f(x)= -0.869375\n",
      "differential_evolution step 40: f(x)= -0.869375\n",
      "differential_evolution step 41: f(x)= -0.869375\n",
      "differential_evolution step 42: f(x)= -0.869375\n",
      "differential_evolution step 43: f(x)= -0.869375\n",
      "differential_evolution step 44: f(x)= -0.869375\n",
      "differential_evolution step 45: f(x)= -0.869375\n",
      "differential_evolution step 46: f(x)= -0.869375\n",
      "differential_evolution step 47: f(x)= -0.869375\n",
      "differential_evolution step 48: f(x)= -0.869375\n",
      "differential_evolution step 49: f(x)= -0.869375\n",
      "differential_evolution step 50: f(x)= -0.869375\n",
      "differential_evolution step 51: f(x)= -0.869375\n",
      "differential_evolution step 52: f(x)= -0.869375\n",
      "differential_evolution step 53: f(x)= -0.869375\n",
      "differential_evolution step 54: f(x)= -0.869375\n",
      "differential_evolution step 55: f(x)= -0.869375\n",
      "differential_evolution step 56: f(x)= -0.869375\n",
      "differential_evolution step 57: f(x)= -0.869375\n",
      "differential_evolution step 58: f(x)= -0.869375\n",
      "differential_evolution step 59: f(x)= -0.869375\n",
      "differential_evolution step 60: f(x)= -0.869375\n",
      "differential_evolution step 61: f(x)= -0.869375\n",
      "differential_evolution step 62: f(x)= -0.869375\n",
      "differential_evolution step 63: f(x)= -0.869375\n",
      "differential_evolution step 64: f(x)= -0.869375\n",
      "differential_evolution step 65: f(x)= -0.869375\n",
      "differential_evolution step 66: f(x)= -0.869375\n",
      "differential_evolution step 67: f(x)= -0.869375\n",
      "differential_evolution step 68: f(x)= -0.869375\n",
      "differential_evolution step 69: f(x)= -0.869375\n",
      "differential_evolution step 70: f(x)= -0.869375\n",
      "differential_evolution step 71: f(x)= -0.869375\n",
      "differential_evolution step 72: f(x)= -0.869375\n",
      "differential_evolution step 73: f(x)= -0.869375\n",
      "differential_evolution step 74: f(x)= -0.869375\n",
      "differential_evolution step 75: f(x)= -0.869375\n",
      "differential_evolution step 76: f(x)= -0.869375\n",
      "differential_evolution step 77: f(x)= -0.869375\n",
      "differential_evolution step 78: f(x)= -0.869375\n",
      "differential_evolution step 79: f(x)= -0.869375\n",
      "differential_evolution step 80: f(x)= -0.869375\n",
      "differential_evolution step 81: f(x)= -0.869375\n",
      "differential_evolution step 82: f(x)= -0.869375\n",
      "differential_evolution step 83: f(x)= -0.869375\n",
      "differential_evolution step 84: f(x)= -0.869375\n",
      "differential_evolution step 85: f(x)= -0.869375\n",
      "differential_evolution step 86: f(x)= -0.869375\n",
      "differential_evolution step 87: f(x)= -0.869375\n",
      "differential_evolution step 88: f(x)= -0.869375\n",
      "differential_evolution step 89: f(x)= -0.869375\n",
      "differential_evolution step 90: f(x)= -0.869375\n",
      "differential_evolution step 91: f(x)= -0.869375\n",
      "differential_evolution step 92: f(x)= -0.869375\n",
      "differential_evolution step 93: f(x)= -0.869375\n",
      "differential_evolution step 94: f(x)= -0.869375\n",
      "differential_evolution step 95: f(x)= -0.869375\n",
      "differential_evolution step 96: f(x)= -0.869375\n",
      "differential_evolution step 97: f(x)= -0.869375\n",
      "differential_evolution step 98: f(x)= -0.869375\n",
      "differential_evolution step 99: f(x)= -0.869375\n",
      "differential_evolution step 100: f(x)= -0.869375\n",
      "Polishing solution with 'L-BFGS-B'\n",
      " message: Maximum number of iterations has been exceeded.\n",
      " success: False\n",
      "     fun: -0.8693753207065397\n",
      "       x: [ 2.355e+02  5.011e-02  3.840e+00]\n",
      "     nit: 100\n",
      "    nfev: 4869\n"
     ]
    }
   ],
   "source": [
    "optimization_res = differential_evolution(func=objective_function, \n",
    "                                          bounds=[(2, 300), (0.0001, 0.5), (2, 10)], \n",
    "                                          updating='deferred',\n",
    "                                          workers=10, \n",
    "                                          disp=True,\n",
    "                                          tol=0.00001,\n",
    "                                          atol=0.00001,\n",
    "                                          maxiter=100,\n",
    "                                          args=(X_train, train_y1, X_test, test_y1))\n",
    "print(optimization_res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:11:48.518110525Z",
     "start_time": "2024-02-23T08:52:54.597175738Z"
    }
   },
   "id": "943c71e4c7e14e11",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([2.35521523e+02, 5.01130182e-02, 3.84020583e+00])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_res.x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:12:46.654442450Z",
     "start_time": "2024-02-23T09:12:46.613739698Z"
    }
   },
   "id": "c617ea1ed43590c9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test metrics ------\n",
      "Mean Squared Error (MSE):              26123859632432.6015625000\n",
      "Root Mean Squared Error (RMSE):        5111150.5194459502\n",
      "Mean Absolute Error (MAE):             2811978.8433588878\n",
      "R-squared (R²):                        0.8692695441\n",
      "Mean Absolute Percentage Error (MAPE): 0.0674873352\n",
      "Max Error (ME):                        24920269.7472040541\n",
      "Median Absolute Error (MedAE):         1326876.1562735289\n",
      "------ train metrics ------\n",
      "Mean Squared Error (MSE):              11262503596302.6855468750\n",
      "Root Mean Squared Error (RMSE):        3355965.3747174875\n",
      "Mean Absolute Error (MAE):             1970045.3433365910\n",
      "R-squared (R²):                        0.9366379782\n",
      "Mean Absolute Percentage Error (MAPE): 0.0491131486\n",
      "Max Error (ME):                        18553272.5825485103\n",
      "Median Absolute Error (MedAE):         1095451.3801190890\n"
     ]
    }
   ],
   "source": [
    "from metrics import print_metrics\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create an instance of GradientBoostingRegressor\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=236, learning_rate=0.050113, max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "gb_regressor.fit(X_train, train_y1)\n",
    "\n",
    "print(\"------ test metrics ------\")\n",
    "print_metrics(test_y1, gb_regressor.predict(X_test))\n",
    "\n",
    "print(\"------ train metrics ------\")\n",
    "print_metrics(train_y1, gb_regressor.predict(X_train))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T09:14:46.362555285Z",
     "start_time": "2024-02-23T09:14:44.831813428Z"
    }
   },
   "id": "98fa02746a5dd0f1",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "45bed6a525b3be7a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
